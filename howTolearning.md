### 학습 관련 기술들 from 밑바닥부터 딥러닝
---
#### INDEX
- 1) 가중치 매개변수의 최적값을 탐색하는 최적화 방법
- 2) 가중치 매개변수 초깃값
- 3) 배치 정규화
- 4) 바른 학습을 위해
    - 오버피팅
    - 가중치 감소
    - 드롭아웃
- 5) 하이퍼 파라미터 설정 방법
---
#### 1. 가중치 매개변수의 최적값을 탐색하는 최적화 방법
- 1.1. SGD
    - 단점: 등방성(anisotropy) 함수(방향에 따라 성질, 즉, 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적임.
        - $W \leftarrow W - \eta \frac{\partial L}{\partial W}  ... (6.3)$
- 1.2. Momentum
    - SGD보다 지그재그 정도가 덜하다. 하지만, y축 방향으로의 속도는 안정적이지 않다.
        - $v \leftarrow \alpha v - \eta \frac{\partial L}{\partial W}  ... (6.3)$
        - $W \leftarrow W + v ...(6.4)$
- 1.3. AdaGrad
    - learning rate는 너무 크면 발산, 적으면 학습이 느리다. --> 적당한 크기가 중요하다.
        - learning rate를 효과적으로 기술로 learning rate decay가 있다. 학습률을 점차 줄여나가는 방법이다.
        - 매개변수 '전체'의 학습률 값을 일괄적으로 낮춘다. 이를 '각각의' 매개변수에 '맞춤형'값을 만들어준다.
        - Adaptive 학습률을 조정하면서 학습을 진행
        - $h \leftarrow \alpha h + \eta \frac{\partial L}{\partial W} \hadamard \frac{\partial L}{\partial W} ... (6.3)$
        - $W \leftarrow W + \eta \frac {1} {sqrt{h}}\frac{\partial L}{\partial W} ...(6.4)$
        - 의미상 매개변수의 원소 중에서 많이 움직인(크게 갱신된) 원소는 합습률이 낮아진다. 갱신이 될수록 갱신량이 적어진다
- 1.4. RMSprop
    - 과거의 모든 기울기를 균일하게 더하는 것이 아니라, 뭔 과거의 기울기는 서서히 잊고 새로운 기울기 정보를 크게 반영한다. 지수이동평균(Exponential moving Average, EMA)라고 하며, 과거 기울기의 반영 규모를 기하급수적으로 감소시킴.
- 1.5. Adam
    - Momentum + AdaGrad 을 융합한 방법.
    - 하이퍼파라미터를 '편향보정' 원논문 Q)참고해서 읽어보기
---    
#### 2. 가중치의 초깃값
- 2.1. 초깃값을 0으로 하면?
    - 학습이 제대로 이루어지지 않는다.
    - weight deday 기법: 가중치 매개변수의 값이 작아지도록 학습하는 방법으로 오버피팅을 피한다.
    - 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문이다.그러므로, 초깃값은 무작위로 해야한다.
- 2.2 은닉층의 활성화 분포
    - 은닉층의 활성화값의 분포를 관찰하면 중요한 정보를 얻을 수 있다.
    - 역전파의 기울기 값이 점점 작아지다가 사라지게 된다. gradient vanishing 문제
    - 각층의 활성화값은 적당히 고루 분포되어야 한다. 층과 층 사이에 적당하게 다양한 데이터가 흐르게 해야 신경망 학습이 효율적으로 이뤄지기 때문이다. 반대로 치우친 데이터 흐르면 데이터 기울기 소실이나 표현력 제한 문제(전부 0.5부근만 반환)에 빠져서 학습이 제대로 이뤄지지 않는다.
    - Xavier 초기값을 사용(대부분 표준으로 사용된다). 활성화값들을 광범위하게 분포시킬 목적이다.
        - 앞의 게층의 노드가 n개 라면 std가 $\frac{1}{sqrt{n}}$인 분포를 사용하면 된다.
        - 앞의 노드 개수가 많을수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼진다.
            - sigmoid 보다 tanh가 더 모양을 유지 잘한다.
    - RELU를 사용할 때의 가중치 초깃값
        - Xavier 초깃값은 활성화 함수가 선형인 것을 전제로 한 것 (sigmoid/tanh는 좌우 대칭함수라 중앙 부근이 선형이다.)
        - RelU를 사용할 때는 ReLU에 특화된 초깃값을 사용하라고 권장
            - He 초깃값: 앞 계층의 노드가 n개일 때, 표준편차가 $\sqrt{\frac{2}{n}}$인 정규분포를 사용함.
---            
#### 3. 배치 정규화
- Batch Normarlization: 각 층이 활성화를 적당히 퍼뜨리도록 '강제'
- 장점
    - 학습이 빨리 진행할 수 있다 (학습 속도 개선)
    - 초깃값에 크게 의존하지 않는다.
    - 오버 피팅을 억제한다 (드랍아웃 등의 필요성 감소)
    - Affine->Batch Norm->ReLU-->Affine->Batch Norm->ReLU ...
    - $\mu_B \leftarrow \frac{1}{m}\sum_{i=1}^m (x_i-\mu_B)^2$
    - $\hat{x_i} \leftarrow \frac{x_i-\mu_i}{\sqrt{\sigma_B^2+\epsilon}} ...(6.7)$
    - $where B = {x_1,x_2,...,x_m} is mini batch, epsilon 은 매우 적은 값(0으로 나누는 것을 방지)$
---    
#### 4. 바른 학습을 위해    
- 4.1 Overfitting
    - 매개변수가 많고 표현력이 높은 모델
    - 훈련 데이터가 적음
- 4.2 Weight decay
    - 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과하여 오버피팅을 억제하는 방법
    - lagrangian multiplier를 통해서 weight값들을 일정 범위로 들어오게 억제(shrink)한다. (L-2 Norm)
- 4.3 Drop out
    - 뉴런을 임의로 삭제하면서 학습하는 방법이다. 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제한다. 
    - test때는 모든 뉴런에 신호를 전달한다. 각 뉴런에 출력에 훈련 때 삭제한 비율을 곱하여 출력함.
        - forward method는 훈련 때만 잘 계산하두면 시험때는 그냥 사용하면 됨. 실제 딥러닝 프레임워크들도 삭제한 비율을 곱하지 않는다.
- 4.4 Ensemble learing
    - 개별적으로 학습시킨 여러 모델의 출력을 평균내어 추론하는 방식
    - Variance를 줄일 수 있다.
---
#### 5. 적절한 하이퍼 파라미터 값 찾기
- hyper parameter
     - 각 층의 뉴런 수 
     - batch size
     - 매개변수 갱신 시의 학습률과 가중치 감소
- 5.1 검증 데이터
    - 하이퍼 파라미터의 성능을 평가 시 시험 데이터를 사용해서는 안됨
        - 하이퍼 파라미터 값이 오버피팅 되기 때문
    - Validation data를 통해 하이퍼 파라미터의 적절성을 평가함
    - 정리
        - Train data: 매개변수 학습 (W)
        - Validation data: 하이퍼 파라미터 성능 평가
        - Test data: 신경망의 범용 성능 평가
    - 하이퍼 파라미터 최적화
        - '최적 값'이 존재하는 범위를 조금씩 줄여나간다.
        - 0단계 : 하이퍼파라미터 값의 범위를 정함
        - 1단계 : 설정된 범위에서 하이퍼파라미터의 값을 무작위로 추출
        - 2단계 : 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가(epoch을 작게 설정)
        - 3단계 : 1단계, 2단계를 특정 횟수 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힘
---